{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49852a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:35.693632Z",
     "iopub.status.busy": "2025-02-23T04:28:35.693632Z",
     "iopub.status.idle": "2025-02-23T04:28:35.707794Z",
     "shell.execute_reply": "2025-02-23T04:28:35.705186Z"
    },
    "papermill": {
     "duration": 0.043956,
     "end_time": "2025-02-23T04:28:35.709703",
     "exception": false,
     "start_time": "2025-02-23T04:28:35.665747",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Dont delete this cell although it is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2245478c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:35.749660Z",
     "iopub.status.busy": "2025-02-23T04:28:35.749660Z",
     "iopub.status.idle": "2025-02-23T04:28:35.765807Z",
     "shell.execute_reply": "2025-02-23T04:28:35.764062Z"
    },
    "papermill": {
     "duration": 0.034869,
     "end_time": "2025-02-23T04:28:35.767815",
     "exception": false,
     "start_time": "2025-02-23T04:28:35.732946",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nr_input_rating = 5\n",
    "nr_input_review = (\n",
    "    \"\\u092f\\u094b \\u0939\\u094b\\u091f\\u0932 \\u0920\\u0917\\u093f \\u0939\\u094b\\u0964\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551ad8e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:35.849299Z",
     "iopub.status.busy": "2025-02-23T04:28:35.849299Z",
     "iopub.status.idle": "2025-02-23T04:28:35.865850Z",
     "shell.execute_reply": "2025-02-23T04:28:35.865850Z"
    },
    "papermill": {
     "duration": 0.04766,
     "end_time": "2025-02-23T04:28:35.872183",
     "exception": false,
     "start_time": "2025-02-23T04:28:35.824523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received Review: यो होटल ठगि हो।\n",
      "Received Rating: 5\n"
     ]
    }
   ],
   "source": [
    "nr_input_review = globals().get('nr_input_review', \"\")  # Default to empty string if not provided\n",
    "nr_input_rating = globals().get('nr_input_rating', 0.0)  # Default to 0.0 if not provided\n",
    "\n",
    "nr_input_rating = int(nr_input_rating)  \n",
    "nr_input_review = str(nr_input_review) \n",
    "\n",
    "# Make sure the nrs are properly received\n",
    "print(f\"Received Review: {nr_input_review}\")\n",
    "print(f\"Received Rating: {nr_input_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463156cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:35.940091Z",
     "iopub.status.busy": "2025-02-23T04:28:35.938082Z",
     "iopub.status.idle": "2025-02-23T04:28:41.528276Z",
     "shell.execute_reply": "2025-02-23T04:28:41.528276Z"
    },
    "papermill": {
     "duration": 5.621698,
     "end_time": "2025-02-23T04:28:41.532071",
     "exception": false,
     "start_time": "2025-02-23T04:28:35.910373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faf315c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:41.570261Z",
     "iopub.status.busy": "2025-02-23T04:28:41.570261Z",
     "iopub.status.idle": "2025-02-23T04:28:44.678050Z",
     "shell.execute_reply": "2025-02-23T04:28:44.678050Z"
    },
    "papermill": {
     "duration": 3.147786,
     "end_time": "2025-02-23T04:28:44.686247",
     "exception": false,
     "start_time": "2025-02-23T04:28:41.538461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Review: यो होटल ठगि हो।\n",
      "Processing Rating: 5\n"
     ]
    }
   ],
   "source": [
    "import papermill as pm\n",
    "import sys\n",
    "\n",
    "# Read input parameters\n",
    "try:\n",
    "    nr_input_review = nr_input_review  # This comes from papermill\n",
    "    nr_input_rating = nr_input_rating\n",
    "except NameError:\n",
    "    nr_input_review = \"Default review\"\n",
    "    nr_input_rating = 5 # Default values for testing\n",
    "\n",
    "print(f\"Processing Review: {nr_input_review}\")\n",
    "print(f\"Processing Rating: {nr_input_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5079e183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:44.734066Z",
     "iopub.status.busy": "2025-02-23T04:28:44.734066Z",
     "iopub.status.idle": "2025-02-23T04:28:44.743793Z",
     "shell.execute_reply": "2025-02-23T04:28:44.743793Z"
    },
    "papermill": {
     "duration": 0.047985,
     "end_time": "2025-02-23T04:28:44.750035",
     "exception": false,
     "start_time": "2025-02-23T04:28:44.702050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_temp_review = nr_input_review\n",
    "nr_temp_rating = nr_input_rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f668159b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:44.785636Z",
     "iopub.status.busy": "2025-02-23T04:28:44.785636Z",
     "iopub.status.idle": "2025-02-23T04:28:44.798458Z",
     "shell.execute_reply": "2025-02-23T04:28:44.798458Z"
    },
    "papermill": {
     "duration": 0.032439,
     "end_time": "2025-02-23T04:28:44.798458",
     "exception": false,
     "start_time": "2025-02-23T04:28:44.766019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Review Predictions\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Review Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e319fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T04:28:44.892947Z",
     "iopub.status.busy": "2025-02-23T04:28:44.891413Z",
     "iopub.status.idle": "2025-02-23T04:28:45.909674Z",
     "shell.execute_reply": "2025-02-23T04:28:45.907668Z"
    },
    "papermill": {
     "duration": 1.051276,
     "end_time": "2025-02-23T04:28:45.909674",
     "exception": true,
     "start_time": "2025-02-23T04:28:44.858398",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Saved Models\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hstack\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "# Load Saved Models\n",
    "\n",
    "import joblib\n",
    "import fasttext\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "try:\n",
    "    print(\"Loading models...\")\n",
    "    svm_model = joblib.load(\"roman_svm_model.pkl\")\n",
    "    tfidf_vectorizer = joblib.load(\"roman_tfidf_vectorizer.pkl\")\n",
    "    word2vec_model = joblib.load(\"roman_word2vec_model.pkl\")\n",
    "    ft_model = fasttext.load_model(\"roman_fasttext_model.bin\")\n",
    "    rf_model = joblib.load(\"roman_rf_model.pkl\")\n",
    "    lr_model = joblib.load(\"roman_lr_model.pkl\")\n",
    "    \n",
    "    \n",
    "    print(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb7b3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c1283",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review = nr_input_review.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ede678",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cdb97",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \n",
    "    text = re.sub(r'\\bu\\b', 'timi', text)  \n",
    "    text = re.sub(r'\\bm\\b', 'ma', text)\n",
    "    text = re.sub(r'\\beka\\b', 'ek', text)\n",
    "\n",
    "    # Remove extra spaces and normalize spacing\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "nr_input_review = normalize_text(nr_input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba915b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59095933",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'nga', '', text)\n",
    "     \n",
    "    return text\n",
    "\n",
    "nr_input_review = remove_noise(nr_input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5bbf6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc58a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def convert_emojis_to_text(text):\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "\n",
    "nr_input_review = convert_emojis_to_text(nr_input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41395266",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c5ca7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_slang(text):\n",
    "    slang_dict = {'thikkk': 'thik', \n",
    "        'ghamta': 'samta', \n",
    "        'farkera': 'pachhi',\n",
    "        'xa': 'cha',\n",
    "        'hoina': 'haina',\n",
    "        'k': 'ke',\n",
    "        'khoi': 'kahaan',\n",
    "        'kati': 'kati',\n",
    "        'k garne': 'ke garne',\n",
    "        'thaxa': 'thaha',\n",
    "        'thaxaina': 'thaha chaina',\n",
    "        'kya': 'kya ho',\n",
    "        'la': 'la',\n",
    "        'hait': 'hait',\n",
    "        'dherai': 'dherai',\n",
    "        'ali': 'ali',\n",
    "        'kasto': 'kasto',\n",
    "        'k cha': 'ke cha',\n",
    "        'kura': 'kura',\n",
    "        'khate': 'khate',\n",
    "        'dai': 'dai',\n",
    "        'didi': 'didi',\n",
    "        'bhai': 'bhai',\n",
    "        'bahini': 'bahini',\n",
    "        'muji': 'muji',\n",
    "        'kukur': 'kukur',\n",
    "        'jasto': 'jasto',\n",
    "        'testo': 'testo',\n",
    "        'yesto': 'yesto',\n",
    "        'kina': 'kina',\n",
    "        'huncha': 'huncha',\n",
    "        'hunna': 'hunna',\n",
    "        'pugyo': 'pugyo',\n",
    "        'pugena': 'pugena',\n",
    "        'khaana': 'khaana',\n",
    "        'khayo': 'khayo',\n",
    "        'khana': 'khana',\n",
    "        'bas': 'bas',\n",
    "        'chhito': 'chhito',\n",
    "        'bholi': 'bholi',\n",
    "        'aaja': 'aaja',\n",
    "        'parla': 'parla',\n",
    "        'pardaina': 'pardaina',\n",
    "        'thik': 'thik',\n",
    "        'thikai': 'thikai',\n",
    "        'ramro': 'ramro',\n",
    "        'naramro': 'naramro',\n",
    "        'khatra': 'khatra',\n",
    "        'halka': 'halka',\n",
    "        'maile': 'maile',\n",
    "        'timi': 'timi',\n",
    "        'huss': 'huss',\n",
    "        'guff': 'guff',\n",
    "        'jhyau': 'jhyau',\n",
    "        'khuro': 'khuro',\n",
    "        'lado': 'lado',\n",
    "        'thulo': 'thulo',\n",
    "        'sano': 'sano',\n",
    "        'khaire': 'khaire',\n",
    "        'jholey': 'jholey',\n",
    "        'fuchhey': 'fuchhey',\n",
    "        'khatey': 'khatey',\n",
    "        'boka': 'boka',\n",
    "        'bokey': 'bokey',\n",
    "        'bokeycha': 'bokeycha',\n",
    "        'bokeko': 'bokeko',\n",
    "        'bokera': 'bokera',\n",
    "        'bokne': 'bokne',\n",
    "        'boknu': 'boknu',\n",
    "        'boknus': 'boknus',\n",
    "        'boknuparne': 'boknuparne',\n",
    "        'boknuparyo': 'boknuparyo',\n",
    "        'boknuparcha': 'boknuparcha',\n",
    "        'xa' : 'cha',\n",
    "        'khai': 'malai tha xaina',\n",
    "        'gr8': 'great',\n",
    "        'bro': 'bhai',\n",
    "        'thik xa': 'thik cha',\n",
    "        'k xa': 'ke cha',\n",
    "        'momo': 'dumpling',\n",
    "    }\n",
    "    for slang, standard in slang_dict.items():\n",
    "        text = text.replace(slang, standard)\n",
    "    return text\n",
    "\n",
    "nr_input_review = handle_slang(nr_input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daace78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c6081",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = ['ra', 'ko', 'le', 'lai', 'bata', 'cha', 'xa', 'yo', 'tiyo', 'mero', 'maile', 'ma' , 'lagi' , 'mana' , 'malai' , 'ho' ,'tara' , 'pani' , 'chan' 'yo', 'ho', 'ra', 'ma', 'cha', 'lai', 'le', 'garna', 'hunxa', 'ko', 'bata', \n",
    "    'ko', 'of', 'a', 'an', 'the', 'is', 'and', 'but' ]\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "nr_input_review = remove_stopwords(nr_input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6cb97",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2215d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "nr_input_review = tokenize(nr_input_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4868bd7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb9f09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "lemmatizer_dict = {\n",
    "    'gardaichha': 'garnu',\n",
    "    'garchha': 'garnu',\n",
    "    'garera': 'garnu',\n",
    "    'garne': 'garnu',\n",
    "    'bhayeko': 'bhayeko',\n",
    "    'jane': 'jan',\n",
    "    'huncha': 'hunu',\n",
    "    'hune': 'hunu',\n",
    "    'pugne': 'pugnu',\n",
    "    'garne': 'garnu',\n",
    "    'chha': 'cha',\n",
    "    'aune': 'aunu',\n",
    "    'jane': 'jan',\n",
    "    'dekhe': 'dekhnus',\n",
    "    'garaune': 'garnu',\n",
    "    'jaane': 'jan'\n",
    "}\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    \n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)  \n",
    "\n",
    "\n",
    "    words = text.split()\n",
    "    lemmatized_words = []\n",
    "\n",
    "    for word in words:\n",
    "        \n",
    "        if word in lemmatizer_dict:\n",
    "            lemmatized_words.append(lemmatizer_dict[word])\n",
    "        else:\n",
    "            lemmatized_words.append(word)\n",
    "\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6031f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nr_input_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eadc504",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_word2vec(text):\n",
    "    words = text.split()\n",
    "    known_words = [word for word in words if word in word2vec_model.wv]\n",
    "    if not known_words:\n",
    "        return np.zeros(100)\n",
    "    return np.mean([word2vec_model.wv[word] for word in known_words], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f413be9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to Convert Text to FastText Features\n",
    "def average_fasttext(text):\n",
    "    words = text.split()\n",
    "    vectors = [ft_model.get_word_vector(word) for word in words if word in ft_model.words]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(300)  # Zero vector if no words match\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccedcee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to Predict Review Authenticity\n",
    "def predict_review(nr_input_review):\n",
    "    try:\n",
    "        print(f\"\\nOriginal Input: {nr_temp_review}\")\n",
    "        print(f\"Review: {nr_temp_rating}\\n\")\n",
    "\n",
    "        # Step 1: Preprocess Text\n",
    "        processed_text = lemmatize(nr_input_review)\n",
    "        \n",
    "\n",
    "        # Step 2: Extract Features\n",
    "        tfidf_features = tfidf_vectorizer.transform([processed_text])\n",
    "       \n",
    "\n",
    "        word2vec_features = np.array([average_word2vec(processed_text)])\n",
    "        \n",
    "\n",
    "        fasttext_features = np.array([average_fasttext(processed_text)])\n",
    "       \n",
    "\n",
    "        # Step 3: Combine Features\n",
    "        try:\n",
    "            combined_features = hstack([tfidf_features, word2vec_features, fasttext_features])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in feature stacking: {e}\")\n",
    "            return\n",
    "\n",
    "        # Step 4: Make Prediction\n",
    "        try:\n",
    "            prediction = svm_model.predict(combined_features)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in prediction: {e}\")\n",
    "            return\n",
    "\n",
    "        # Step 5: Get Probability Score (if available)\n",
    "        try:\n",
    "            probability = svm_model.predict_proba(combined_features)[0][prediction]\n",
    "            print(f\"Predicted Review Authenticity: {'REAL' if prediction == 1 else 'FAKE'} (Confidence: {probability:.2f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in probability calculation: {e}\")\n",
    "            probability = None  # Some models don’t support predict_proba()\n",
    "\n",
    "        return \"REAL\" if prediction == 1 else \"FAKE\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8d264",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result = predict_review(' '.join(nr_input_review))  # Ensure input is a string\n",
    "print(f\"Final Prediction: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.17104,
   "end_time": "2025-02-23T04:28:47.057192",
   "environment_variables": {},
   "exception": true,
   "input_path": "file.ipynb",
   "output_path": "file_OUTPUT.ipynb",
   "parameters": {
    "nr_input_rating": 5,
    "nr_input_review": "यो होटल ठगि हो।"
   },
   "start_time": "2025-02-23T04:28:27.886152",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
